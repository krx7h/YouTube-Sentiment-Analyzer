{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pytubefix import YouTube\n",
        "def trans(url):\n",
        "  yt = YouTube(url)\n",
        "  for caption in yt.captions:\n",
        "      print(caption)\n",
        "\n",
        "  caption = yt.captions.get_by_language_code('en')\n",
        "  if caption is None:\n",
        "      caption = yt.captions.get_by_language_code('a.en')\n",
        "  if caption:\n",
        "      srt_captions = caption.generate_srt_captions()\n",
        "\n",
        "      # Save to file\n",
        "      with open(\"transcript.srt\", \"w\", encoding='utf-8') as f:\n",
        "          f.write(srt_captions)\n",
        "      print(\"Transcript saved to transcript.srt\")\n",
        "  else:\n",
        "      print(\"English or auto-generated English captions not found.\")"
      ],
      "metadata": {
        "id": "_mJriYMA0bj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_srt_file(input_path, output_path):\n",
        "    with open(input_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    clean_lines = []\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line.isdigit():\n",
        "            continue\n",
        "        if '-->' in line:\n",
        "            continue\n",
        "        if line == '':\n",
        "            continue\n",
        "        clean_lines.append(line)\n",
        "\n",
        "    with open(output_path, 'w', encoding='utf-8') as file:\n",
        "        for line in clean_lines:\n",
        "            file.write(line + '\\n')\n"
      ],
      "metadata": {
        "id": "CY8OVhirldmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean2():\n",
        "  with open(\"clean_transcript.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "      content = file.read()\n",
        "\n",
        "  # Replace newlines with spaces\n",
        "  clean_text = content.replace('\\n', ' ')\n",
        "\n",
        "  # Split the text by full stops\n",
        "  sentences = clean_text.split('.')\n",
        "\n",
        "  # Open the output file in append mode\n",
        "  with open(\"hello.txt\", \"a\", encoding=\"utf-8\") as outfile:\n",
        "      for sentence in sentences:\n",
        "          sentence = sentence.strip()\n",
        "          if sentence:  # skip empty sentences\n",
        "              outfile.write(sentence + \".\\n\")"
      ],
      "metadata": {
        "id": "5WZGbPZXuTuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred():\n",
        "  from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  ndf = pd.read_csv(\"clean_ds.csv\",encoding='ISO-8859-1')\n",
        "  ndf['text'] = ndf['text'].fillna('')\n",
        "  X = ndf['text']\n",
        "  y = ndf['sentiment']\n",
        "  with open('hello.txt', 'r', encoding='utf-8') as file:\n",
        "      lines = file.readlines()\n",
        "  from sklearn.tree import DecisionTreeClassifier\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  import pandas as pd\n",
        "\n",
        "  ndf = pd.read_csv(\"processed.csv",encoding='ISO-8859-1')\n",
        "  ndf['text'] = ndf['text'].fillna('')\n",
        "  X = ndf['text']\n",
        "  y = ndf['sentiment']\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  X_train_vec = vectorizer.fit_transform(X_train)\n",
        "  X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "  model = LogisticRegression()\n",
        "  model.fit(X_train_vec, y_train)\n",
        "  X2 = ndf['text']\n",
        "  y2 = ndf['sentiment']\n",
        "  vectorizer = TfidfVectorizer()\n",
        "\n",
        "  global pos\n",
        "  pos = 0\n",
        "  global neg\n",
        "  neg = 0\n",
        "  global neu\n",
        "  neu = 0\n",
        "  for line in lines:\n",
        "      X_test = [line.strip()]\n",
        "      X_test_vec = vectorizer.transform(X_test)\n",
        "      y_pred = model.predict(X_test_vec)\n",
        "      if y_pred == 'positive':\n",
        "        pos = pos + 1\n",
        "      elif y_pred == 'negative':\n",
        "        neg = neg + 1\n",
        "      else:\n",
        "        neu = neu + 1\n",
        "      print(X_test,y_pred)\n"
      ],
      "metadata": {
        "id": "jtFGIKSDA32x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "def plot():\n",
        "  print(pos,neg,neu)\n",
        "  import matplotlib.pyplot as plt\n",
        "  sentiment_counts = [pos, neg, neu]\n",
        "  sentiment_labels = ['Positive', 'Negative', 'Neutral']\n",
        "\n",
        "  # Create the bar chart\n",
        "  plt.bar(sentiment_labels, sentiment_counts, color=['green', 'red', 'gray'])\n",
        "\n",
        "  plt.title('Sentiment Distribution in Transcript')\n",
        "  plt.xlabel('Sentiment')\n",
        "  plt.ylabel('Count')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "D-phrGBPqqpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = input(\"Enter the YouTube URL: \")\n",
        "\n",
        "trans(url)\n",
        "clean_srt_file('transcript.srt', 'clean_transcript.txt')\n",
        "clean2()\n",
        "pred()\n",
        "plot()"
      ],
      "metadata": {
        "id": "IsUQaiE8vS08"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
